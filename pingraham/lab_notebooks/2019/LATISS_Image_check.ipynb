{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to be used to test that ATCamera, ATHeaderService and ATArchiver are online and working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lsst.ts import salobj\n",
    "import asyncio\n",
    "from astropy.io import fits\n",
    "\n",
    "import warnings\n",
    "#import matplotlib.pyplot as plt  # imported as py above\n",
    "from astropy.modeling import models, fitting\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from matplotlib import pyplot as plt\n",
    "#%matplotlib ipympl\n",
    "plt.rcParams['figure.figsize'] = [7, 6]\n",
    "\n",
    "import lsst.daf.persistence as dafPersist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import lsst.afw.display as afwDisplay\n",
    "\n",
    "afwDisplay.setDefaultBackend('matplotlib')\n",
    "import time\n",
    "import lsst.afw.cameraGeom.utils as cameraGeomUtils\n",
    "import lsst.geom\n",
    "\n",
    "import os\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\n",
    "logger = logging.getLogger('image_display_notebook')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to display in firefly?\n",
    "# first open a tunnel\n",
    "## ssh -L 8000:10.0.100.230:8080 pingraham@140.252.32.143\n",
    "afwDisplay.setDefaultBackend('firefly')\n",
    "os.environ['FIREFLY_HTML'] = \"slate.html\"\n",
    "os.environ['FIREFLY_URL'] = 'http://10.0.100.230:8080/firefly'\n",
    "# now open a tab and navigate to http://localhost:8000/firefly/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup the butler\n",
    "#accs_images = True\n",
    "accs_images = False\n",
    "if accs_images:\n",
    "    repo = os.path.join(\"/home/saluser/ingest/accs/\")#, mapper={'calibRoot': \"/home/saluser/ingest/dmcs/CALIB\"})\n",
    "    butler = dafPersist.Butler(repo)\n",
    "else:\n",
    "    #repo = os.path.join(\"/home/saluser/ingest/dmcs/\")#, mapper={'calibRoot': \"/home/saluser/ingest/dmcs/CALIB\"})\n",
    "    repo = os.path.join(\"/home/saluser/ingest/dmcs/\")\n",
    "    butler = dafPersist.Butler(repo) #\n",
    "    #butler = dafPersist.Butler(repo, mapper=\"lsst.obs.lsst.auxTel.AuxTelMapper\")\n",
    "#test   \n",
    "raw = butler.get(\"raw\", visit=2019111300004)\n",
    "image = raw.getImage().array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-13 17:45:42,130 ATArchiver   INFO     Read historical data in 11.17 sec\n",
      "2019-11-13 17:45:44,409 ATCamera     INFO     Read historical data in 0.01 sec\n"
     ]
    }
   ],
   "source": [
    "d = salobj.Domain()\n",
    "\n",
    "ATArchiver = salobj.Remote(d, 'ATArchiver')\n",
    "await ATArchiver.start_task\n",
    "ATCamera = salobj.Remote(d, 'ATCamera')\n",
    "await ATCamera.start_task\n",
    "#ATMonochromator = salobj.Remote(SALPY_ATMonochromator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-13 17:45:48,376 ATCamera     INFO     Read historical data in 0.01 sec\n",
      "2019-11-13 17:45:48,781 ATSpectrograph INFO     Read historical data in 0.41 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lsst.ts.standardscripts.auxtel.latiss import LATISS\n",
    "\n",
    "latiss = LATISS(salobj.Remote(domain=d, name=\"ATCamera\"), \n",
    "                salobj.Remote(domain=d, name=\"ATSpectrograph\"))\n",
    "\n",
    "await asyncio.gather(latiss.atcam.start_task, latiss.atspec.start_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp = await latiss.take_bias(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave this cell for state transitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp=await ATArchiver.cmd_enable.start(timeout=10)\n",
    "# tmp.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed withs ack=-300,ack.error=0, ackcmd.result=Ack : NO Command not accepted in State{SummaryState = ENABLED}\n"
     ]
    }
   ],
   "source": [
    "#  bring into enable state if required\n",
    "if True:\n",
    "    try:\n",
    "        await ATCamera.cmd_enable.start(timeout=15)\n",
    "    except salobj.AckError as ack_err:\n",
    "        tmp=ack_err\n",
    "        print(f\"Failed withs ack={tmp.ackcmd.ack},ack.error={tmp.ackcmd.error}, ackcmd.result={tmp.ackcmd.result}\")\n",
    "else:\n",
    "    print('Ignoring')\n",
    "#asyncio.get_event_loop().run_until_complete(ATCamera.cmd_start.start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-13 19:07:05,983 ATSpectrograph WARNING  RemoteEvent(ATSpectrograph, 0, heartbeat) falling behind; read 75 messages\n",
      "2019-11-13 19:07:06,042 ATArchiver   WARNING  RemoteEvent(ATArchiver, 0, heartbeat) falling behind; read 75 messages\n",
      "2019-11-13 19:07:06,098 ATSpectrograph WARNING  RemoteEvent(ATSpectrograph, 0, logMessage) falling behind; read 100 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATCamera Wrote file AT_O_20191113_000027\n",
      "AT_O_20191113_000026--R00S00.fits is successfuly transferred to ARC@10.0.100.128:/data/staging/atforwarder/2019-11-13/AT_O_20191113_000026--R00S00.fits\n"
     ]
    }
   ],
   "source": [
    "# Take image\n",
    "\n",
    "#First flush events that we want to listen to\n",
    "ATArchiver.evt_processingStatus.flush()\n",
    "ATCamera.evt_endReadout.flush()\n",
    "\n",
    "group_id='Test'\n",
    "expTime=60.0\n",
    "ATCamera.cmd_takeImages.set(expTime=expTime, shutter=0, numImages=1, imageType='DARK', groupId='test')\n",
    "\n",
    "try:\n",
    "    await ATCamera.cmd_takeImages.start(timeout=expTime+15)\n",
    "except salobj.AckError as ack_err:\n",
    "    print(f\"Failed withs ack={ack_err.ackcmd.ack},ack.error={ack_err.ackcmd.error}, ackcmd.result={ack_err.ackcmd.result}\")\n",
    "\n",
    "endReadout = await ATCamera.evt_endReadout.next(flush=False, timeout=30)\n",
    "print('ATCamera Wrote file {}'.format(endReadout.imageName) )\n",
    "# wait for Archiver\n",
    "test= await ATArchiver.evt_processingStatus.next(flush=False, timeout=30)\n",
    "print(test.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the file manually\n",
    "# dir = '/mnt/data/ats/mcm/20191113/'\n",
    "# atcamera_fname=endReadout.imageName\n",
    "\n",
    "# full_file_name=dir+atcamera_fname+'.fits'\n",
    "# print('Opening {}'.format(full_file_name))\n",
    "# hdu_list = fits.open(full_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hdu_list[0].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = hdu_list[7].data\n",
    "# plt.hist(data[100:300,100:300], bins=10) \n",
    "# #plot.axis([50, 110, 0, 0.06]) \n",
    "# #axis([xmin,xmax,ymin,ymax])\n",
    "# plt.xlabel('pixel value')\n",
    "# plt.ylabel('Occurances')\n",
    "# plt.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils.processExposure \n",
    "importlib.reload(utils.processExposure)\n",
    "from utils.processExposure import processExposure\n",
    "\n",
    "# import utils.grabATImage \n",
    "# importlib.reload(utils.grabATImage)\n",
    "# from utils.grabATImage import grabATImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019111300027\n"
     ]
    },
    {
     "ename": "NoResults",
     "evalue": "No locations for get: datasetType:raw_hdu dataId:DataId(initialdata={'visit': 2019111300027}, tag=set())",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNoResults\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-c643ad53d7f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# have to redefine butler after each image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mbutler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdafPersist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mButler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mexposure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbutler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisitID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#image = raw.getImage().array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/lsst/software/stack/stack/miniconda3-4.5.12-4d7b902/Linux64/daf_persistence/18.1.0-1-g5e4b7ea+11/python/lsst/daf/persistence/butler.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, datasetType, dataId, immediate, **rest)\u001b[0m\n\u001b[1;32m   1394\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasetType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minnerCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimmediate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mReadProxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/lsst/software/stack/stack/miniconda3-4.5.12-4d7b902/Linux64/daf_persistence/18.1.0-1-g5e4b7ea+11/python/lsst/daf/persistence/butler.py\u001b[0m in \u001b[0;36mcallback\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1394\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasetType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minnerCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimmediate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/lsst/software/stack/stack/miniconda3-4.5.12-4d7b902/Linux64/daf_persistence/18.1.0-1-g5e4b7ea+11/python/lsst/daf/persistence/butler.py\u001b[0m in \u001b[0;36mcallback\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanStandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasetType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m             \u001b[0minnerCallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/lsst/software/stack/stack/miniconda3-4.5.12-4d7b902/Linux64/daf_persistence/18.1.0-1-g5e4b7ea+11/python/lsst/daf/persistence/butler.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m   1581\u001b[0m                     \u001b[0mcomponentInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponentInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasetType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimmediate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m                     \u001b[0mcomponentInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m                 \u001b[0massembler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massembler\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgenericAssembler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/lsst/software/stack/stack/miniconda3-4.5.12-4d7b902/Linux64/daf_persistence/18.1.0-1-g5e4b7ea+11/python/lsst/daf/persistence/butler.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, datasetType, dataId, immediate, **rest)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_locate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNoResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No locations for get:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasetType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Get type=%s keys=%s from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasetType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoResults\u001b[0m: No locations for get: datasetType:raw_hdu dataId:DataId(initialdata={'visit': 2019111300027}, tag=set())"
     ]
    }
   ],
   "source": [
    "# parse out visitID from filename - this is highly annoying\n",
    "tmp=endReadout.imageName.split('_')\n",
    "prefix=tmp[2] # dayobs without the dashes\n",
    "\n",
    "# Don't remember why I used int here... whitespace? \n",
    "# surely fixable but bigger fish.\n",
    "suffix='{:05d}'.format(int(tmp[3].split('-')[0])) # SEQNUM, but need to trim extra 0 in obsid\n",
    "visitID = int((prefix+suffix))\n",
    "print(visitID)\n",
    "\n",
    "# Grab image from butler, but need to wait to ingestion so use this polling function\n",
    "#exposure = await grabATImage(visitID, repo, timeout = 40, poll_freq_hz=2)\n",
    "\n",
    "#visitID = int(2019111300021)\n",
    "# have to redefine butler after each image\n",
    "butler = dafPersist.Butler(repo)\n",
    "exposure = butler.get(\"raw\", visit=visitID)\n",
    "#image = raw.getImage().array\n",
    "\n",
    "# do ISR correction\n",
    "isr_corr_exposure = processExposure(exposure, repo=repo)\n",
    "#isr_corr_exposure = exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only here for me to debug, should be up top with other declarations\n",
    "import importlib\n",
    "import utils.findNarrowbandRonchiPeaks\n",
    "importlib.reload(utils.findNarrowbandRonchiPeaks)\n",
    "from utils.findNarrowbandRonchiPeaks import findNarrowbandRonchiPeaks\n",
    "\n",
    "import utils.fitExposure\n",
    "importlib.reload(utils.fitExposure)\n",
    "from utils.fitExposure import fit2DGaussian\n",
    "\n",
    "import utils.calc_CofM\n",
    "importlib.reload(utils.calc_CofM)\n",
    "from utils.calc_CofM import calc_CofM\n",
    "\n",
    "import utils.calc_encircled_energy\n",
    "importlib.reload(utils.calc_encircled_energy)\n",
    "from utils.calc_encircled_energy import calc_encircled_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source detection libraries\n",
    "from lsst.meas.algorithms.detection import SourceDetectionTask\n",
    "import lsst.afw.table as afwTable\n",
    "\n",
    "# create the output table for source detection\n",
    "schema = afwTable.SourceTable.makeMinimalSchema()\n",
    "config = SourceDetectionTask.ConfigClass()\n",
    "config.thresholdValue = 10  # detection threshold after smoothing\n",
    "sourceDetectionTask = SourceDetectionTask(schema=schema, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-13 19:08:35,361 requests.packages.urllib3.connectionpool INFO     Starting new HTTP connection (1): 10.0.100.230\n"
     ]
    }
   ],
   "source": [
    "if True: # display the image in firefly\n",
    "    plt.close('all')\n",
    "    disp = afwDisplay.Display(2, reopenPlot=True)\n",
    "    disp.setMaskPlaneColor('SAT', afwDisplay.IGNORE)\n",
    "    disp.setImageColormap('gray')\n",
    "    disp.scale('linear', 'zscale')\n",
    "    disp.mtv(isr_corr_exposure, title='visit = {}'.format(visitID))\n",
    "    #cgUtils.overlayCcdBoxes(isr_corr_exposure.getDetector(), isTrimmed=True, display=disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-c1b62d060d99>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# parse out visitID from filename - this is highly annoying\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Processing file {} of {}, filename={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# dayobs without the dashes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Don't remember why I used int here... whitespace?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_list' is not defined"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-13 19:08:37,834 ATArchiver   WARNING  RemoteEvent(ATArchiver, 0, heartbeat) falling behind; read 29 messages\n",
      "2019-11-13 19:08:37,864 ATSpectrograph WARNING  RemoteEvent(ATSpectrograph, 0, logMessage) falling behind; read 84 messages\n"
     ]
    }
   ],
   "source": [
    "# I don't like looping but I don't know how to handle multiple files yet!\n",
    "# Declare approximation of where the zero-order star is\n",
    "zeroth_order_estimate = lsst.geom.Point2D(1700,1960)\n",
    "zeroth_order_estimate = lsst.geom.Point2D(1650,1930)\n",
    "zeroth_order_estimate = lsst.geom.Point2D(2100,2100)\n",
    "\n",
    "fit_data=[]\n",
    "\n",
    "for index, img_name in enumerate(image_list):\n",
    "    # parse out visitID from filename - this is highly annoying\n",
    "    print('Processing file {} of {}, filename={}'.format(index,len(image_list), img_name))\n",
    "    tmp=img_name.split('_')\n",
    "    prefix=tmp[2] # dayobs without the dashes\n",
    "    # Don't remember why I used int here... whitespace? \n",
    "    # surely fixable but bigger fish.\n",
    "    suffix='{:05d}'.format(int(tmp[3].split('-')[0])) # SEQNUM, but need to trim extra 0 in obsid\n",
    "    visitID = int((prefix+suffix))\n",
    "    dataId1 = {'visit': visitID}\n",
    "    #multi_file_dataset[i]['visitID']=visitID\n",
    "    \n",
    "    #exposure = butler.get('raw', **dataId1)\n",
    "    exposure = await grabATImage(visitID, repo, timeout = 40, poll_freq_hz=2)\n",
    "    # do ISR correction\n",
    "    isr_corr_exposure = processExposure(exposure, repo=repo, bias=None, defects=None)\n",
    "    \n",
    "    if True: # display the image in firefly\n",
    "        plt.close('all')\n",
    "        disp = afwDisplay.Display(2, reopenPlot=True)\n",
    "        disp.setMaskPlaneColor('SAT', afwDisplay.IGNORE)\n",
    "        disp.setImageColormap('gray')\n",
    "        disp.scale('linear', 'zscale')\n",
    "        disp.mtv(isr_corr_exposure, title='visit = {}'.format(visit_int))\n",
    "        cgUtils.overlayCcdBoxes(isr_corr_exposure.getDetector(), isTrimmed=True, display=disp)\n",
    "    \n",
    "    # Find all sources in the image\n",
    "    tab = afwTable.SourceTable.make(schema)\n",
    "    result = sourceDetectionTask.run(tab, isr_corr_exposure, sigma=2.1)\n",
    "    \n",
    "    # Find the correct sources\n",
    "    zeroth_order_star_BBox= lsst.geom.Box2I.makeCenteredBox(zeroth_order_estimate, lsst.geom.Extent2I(200,200)) \n",
    "    # wavelength solution is bad for the fiberSpectrograph, but close enough for this to work\n",
    "    # can use the monochromator wavelength which is better, but that's not the correct way in the long run\n",
    "\n",
    "    dispersion = (1/0.6358) # pixels/nm\n",
    "    spectral_position_angle=0.0107 # radians clockwise from top\n",
    "\n",
    "    # Find 0th and +/- 1 order peaks \n",
    "    sources = result.sources\n",
    "    center_source, peak1, peak2 = findNarrowbandRonchiPeaks(sources, zeroth_order_star_BBox, wavelength, dispersion, spectral_position_angle)\n",
    "    \n",
    "    # Fit peaks\n",
    "    # zeroth order\n",
    "    # variables names are weird here because I can't think of a clever way to have -1 and +1 as variable names\n",
    "    \n",
    "    bbox0 = lsst.geom.Box2I.makeCenteredBox(center_source.getFootprint().getCentroid(), lsst.geom.Extent2I(100,100)) \n",
    "    peak0_subim = isr_corr_exposure.subset(bbox0)\n",
    "    p0, x0 , y0 = fit2DGaussian(peak0_subim, plot=True)\n",
    "    p0_x_CofM, p0_y_CofM = calc_CofM(peak0_subim) # 2167,3372\n",
    "\n",
    "    # Calculate EE and CofM\n",
    "    p0_EE_rad50_pix, p0_EE_rad67_pix, p0_EE_rad80_pix = calc_encircled_energy(peak0_subim, plot=False) \n",
    "    fit_data.append(p0_EE_rad80_pix)\n",
    "\n",
    "#     # offset to test\n",
    "#     bbox1 = lsst.geom.Box2I.makeCenteredBox(peak1.getFootprint().getCentroid(), lsst.geom.Extent2I(50,50)) \n",
    "#     peak1_subim = isr_corr_exposure.subset(bbox1)\n",
    "#     p1, x1 , y1 = fit2DGaussian(peak1_subim, plot=True)\n",
    "#     p1_x_CofM, p1_y_CofM = calc_CofM(peak1_subim) # 2167,3372\n",
    "\n",
    "#     # Calculate EE and CofM\n",
    "#     p1_EE_rad50_pix, p1_EE_rad67_pix, p1_EE_rad80_pix = calc_encircled_energy(peak1_subim, plot=False) \n",
    "    \n",
    "#     fit_data.append(p1_EE_rad80_pix)\n",
    "#     bbox2 = lsst.geom.Box2I.makeCenteredBox(peak2.getFootprint().getCentroid(), lsst.geom.Extent2I(50,50)) \n",
    "#     peak2_subim = isr_corr_exposure.subset(bbox2)\n",
    "#     p2, x2 , y2 = fit2DGaussian(peak2_subim, plot=False)\n",
    "#     p2_x_CofM, p2_y_CofM = calc_CofM(peak2_subim) # 2167,3372\n",
    "\n",
    "#     # Calculate EE and CofM\n",
    "#     p0_EE_rad50_pix, p0_EE_rad67_pix, p0_EE_rad80_pix = calc_encircled_energy(peak0_subim, plot=False) \n",
    "#     p1_EE_rad50_pix, p1_EE_rad67_pix, p1_EE_rad80_pix = calc_encircled_energy(peak1_subim, plot=False) \n",
    "#     p2_EE_rad50_pix, p2_EE_rad67_pix, p2_EE_rad80_pix = calc_encircled_energy(peak2_subim, plot=False) \n",
    "\n",
    "#     #  Now use multi_file_dataset\n",
    "#     multi_file_dataset[i]['Gauss_x_peak'] = (p0.x_mean.value, p1.x_mean.value, p2.x_mean.value)\n",
    "#     multi_file_dataset[i]['Gauss_y_peak'] = (p0.y_mean.value, p1.y_mean.value, p2.y_mean.value)\n",
    "#     multi_file_dataset[i]['Gauss_xsigma_pix'] = (p0.x_stddev.value, p1.x_stddev.value, p2.x_stddev.value) \n",
    "#     multi_file_dataset[i]['Gauss_ysigma_pix'] = (p0.y_stddev.value, p1.y_stddev.value, p2.y_stddev.value)\n",
    "#     multi_file_dataset[i]['x_CofM'] = (p0_x_CofM, p1_x_CofM, p2_x_CofM)\n",
    "#     multi_file_dataset[i]['y_CofM'] = (p0_y_CofM, p1_y_CofM, p2_y_CofM)\n",
    "#     multi_file_dataset[i]['EE50_pix'] = (p0_EE_rad50_pix, p1_EE_rad50_pix, p2_EE_rad50_pix)\n",
    "#     multi_file_dataset[i]['EE67_pix'] = (p0_EE_rad67_pix, p1_EE_rad67_pix, p2_EE_rad67_pix)\n",
    "#     multi_file_dataset[i]['EE80_pix'] = (p0_EE_rad80_pix, p1_EE_rad80_pix, p2_EE_rad80_pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import lsst_python_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a line to the profile\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "xdata=focus_vals #[3:9]\n",
    "ydata = fit_data #[3:9]\n",
    "\n",
    "def parabola(x,b, x0, a):\n",
    "    return b + a*(x-x0)**2 \n",
    "\n",
    "popt,pcov = curve_fit(parabola, xdata, ydata, p0=[3.0, 69.5 , 1])\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(13, 5))\n",
    "plt.ylabel('Encircled Energy [pix]')\n",
    "plt.plot(xdata, ydata, '.')\n",
    "x=np.arange(np.min(xdata), np.max(xdata), np.abs(np.max(xdata) - np.min(xdata))/100 )\n",
    "plt.plot(x, parabola(x, *popt))\n",
    "plt.title('Encircled Energy [pix]')\n",
    "plt.xlabel('Focus position [mm]')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print('Best focus occurs at {} [mm]'.format(popt[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loop of a bunch of biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1\n",
    "start_time=np.empty(n)\n",
    "camera_time=np.empty(n)\n",
    "exposure_command_completed_time=np.empty(n)\n",
    "archiver_time=np.empty(n)\n",
    "\n",
    "for i in np.arange(n):\n",
    "    # Take image\n",
    "    print('starting image {}'.format(i))\n",
    "    #First flush archiver event\n",
    "    ATArchiver.evt_processingStatus.flush()\n",
    "\n",
    "    group_id='Test'\n",
    "    #ATCamera.cmd_takeImages.set(expTime=20.0, shutter=1, numImages=1, imageSequenceName=group_id)\n",
    "    ATCamera.cmd_takeImages.set(expTime=0.0, shutter=0, numImages=1, imageSequenceName=group_id)\n",
    "\n",
    "    start_time[i]=time.time()\n",
    "    try:\n",
    "        asyncio.get_event_loop().run_until_complete(ATCamera.cmd_takeImages.start(timeout=30))\n",
    "    except salobj.AckError as ack_err:\n",
    "        print(f\"Failed with ack.result={ack_err.ack.result}\")\n",
    "    exposure_command_completed_time[i]=time.time()\n",
    "    endReadout = asyncio.get_event_loop().run_until_complete(ATCamera.evt_endReadout.next(flush=True, timeout=30))\n",
    "    print('ATCamera Wrote file {}'.format(endReadout.imageName) )\n",
    "    camera_time[i]=time.time()\n",
    "\n",
    "    test=asyncio.get_event_loop().run_until_complete(ATArchiver.evt_processingStatus.next(flush=False, timeout=60))\n",
    "    print(test.description)\n",
    "    archiver_time[i]=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ATCamera time to write file [s]: {}'.format(camera_time[0]-exposure_command_completed_time[0]))\n",
    "print('Archiver time to write file [s]: {}'.format(archiver_time[0]-exposure_command_completed_time[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x = camera_time-exposure_command_completed_time\n",
    "plt.hist(x, bins=50)#, density=0.01)\n",
    "plt.ylabel('Occurances')\n",
    "plt.xlabel('Camera Timing [s]')\n",
    "plt.title('Time of image writing from end of takeImage command completion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "y = archiver_time-exposure_command_completed_time\n",
    "plt.hist(y, bins=50)#, density=0.01)\n",
    "plt.ylabel('Occurances')\n",
    "plt.xlabel('Archiver Timing [s]')\n",
    "plt.title('Time of image writing from end of takeImage command completion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=x\n",
    "y0=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_time[0]-exposure_command_completed_time[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "await asyncio.sleep(1)\n",
    "end_time = time.time()\n",
    "print(start_time)\n",
    "print(end_time)\n",
    "print('net time [s]: {}'.format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
