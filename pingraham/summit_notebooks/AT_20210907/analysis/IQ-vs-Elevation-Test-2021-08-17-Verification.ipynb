{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to verify the hexapod LUT\n",
    "## This is for data taken on 2021-09-09 which goes up/down taking data in imaging mode only.\n",
    "## This is seq_num 510-533\n",
    "## Notebook finds stars and determines a PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio \n",
    "import matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "from astropy.time import Time, TimeDelta\n",
    "\n",
    "from lsst_efd_client import EfdClient, resample, rendezvous_dataframes\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efd_client = EfdClient('summit_efd')\n",
    "#efd_client = EfdClient('ldf_stable_efd') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find data\n",
    "Query for all the `endReadout` events on the timespan of the night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date='20210909'\n",
    "test='IQ_vs_elevation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='initial'\n",
    "\n",
    "if run == 'initial':\n",
    "    t1_set = Time(\"2021-09-10T05:14:44\", format='isot', scale='tai')\n",
    "    t2_set = Time(\"2021-09-10T05:35:50\", format='isot', scale='tai')\n",
    "#     start_log_msg = '[2021-07-08_Repeat_Focus_Test_START]'\n",
    "#     finish_log_msg = '[2021-07-08_Repeat_Focus_Test_END]'\n",
    "elif run == 'iter2': \n",
    "    t1_set = Time(\"2021-08-18T10:12:00\", format='isot', scale='tai')\n",
    "    t2_set = Time(\"2021-08-18T10:35:44\", format='isot', scale='tai')\n",
    "else:\n",
    "    raise IOError('input not valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = Time(Time.now(), format='isot', scale='tai')\n",
    "print(f'time is {time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_readout = await efd_client.select_time_series(\"lsst.sal.ATCamera.logevent_endReadout\", \n",
    "                                           [\"imageName\", \"requestedExposureTime\", \"additionalKeys\",\n",
    "                                            \"additionalValues\",\"timestampAcquisitionStart\",\"timestampEndOfReadout\"], t1_set, t2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base0 = await efd_client.select_time_series(\"lsst.sal.Script.logevent_logMessage\", \n",
    "#                                            [\"message\",\"level\"], t1_set, t2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(base0.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the start/end sequences and trim the bad ones\n",
    "# base = base0[(base0.message.str.find(start_log_msg) != -1) | (base0.message.str.find(finish_log_msg) != -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop false starts\n",
    "# if run == 'initial':\n",
    "#     time_reg = '2021-07-09 02:41:02.488000+00:00'\n",
    "#     ind=base.index.get_loc(time_reg, method='nearest')\n",
    "#     base.drop(base.index[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now match each entry. For each `i` item with `intra` in the name, there must be an `i+1` with `extra` otherwise it is not a pair. \n",
    "A pair also has the same groupID\n",
    "The image before the pair is an in-focus image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_images = []\n",
    "extra_images = []\n",
    "in_focus_images = []\n",
    "intra_times = []\n",
    "extra_times = []\n",
    "in_focus_times = []\n",
    "intra_exptimes = []\n",
    "extra_exptimes = []\n",
    "in_focus_exptimes = []\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "npairs = 0\n",
    "nmiss = 0\n",
    "\n",
    "while i < len(end_readout)-3:\n",
    "    in_focus_20s = end_readout['imageName'][i]\n",
    "    in_focus_exp_time = end_readout['requestedExposureTime'][i]\n",
    "    #skip known bad files\n",
    "    # 198 and 199 find different sources...\n",
    "    bad_list=[]\n",
    "    if in_focus_20s in bad_list or in_focus_exp_time != 30:\n",
    "        i+=1\n",
    "        continue\n",
    "\n",
    "    df_tmp=pd.DataFrame({\n",
    "                         'inFocus20s':end_readout['imageName'][i],\n",
    "                         # Need times during cwfs for telescope position\n",
    "                         'inFocusExpTime20s':end_readout['requestedExposureTime'][i],\n",
    "                         'inFocustimestampEndOfReadout':end_readout['timestampEndOfReadout'][i],\n",
    "                         'intraExtratimestampAcquisitionStart':end_readout['timestampAcquisitionStart'][i],\n",
    "                         'intraExtratimestampEndOfReadout':end_readout['timestampEndOfReadout'][i],\n",
    "                        }, index=[end_readout.index[i]])\n",
    "    df=df.append(df_tmp)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe with new values of interest and we'll join them post-facto\n",
    "df_offsets=pd.DataFrame()\n",
    "# Populate the data structure from the pairs found above\n",
    "for i in range(len(df.index)):\n",
    "    \n",
    "    # Determine time stamps for searching for metadata\n",
    "    # include ability to correct for TAI if required, but set to zero for the moment\n",
    "\n",
    "#    t1 = Time(in_focus_times[i], scale='tai') - TimeDelta(in_focus_exptimes[i], format='sec', scale='tai')\n",
    "#    t2 = Time(extra_times[i], scale='tai') - TimeDelta(2., format='sec', scale='tai')\n",
    "    \n",
    "    # want time during CWFS sensing for telescope position\n",
    "    t1 = Time(df['intraExtratimestampAcquisitionStart'][i], format='unix_tai') \n",
    "    t2 = Time(df['intraExtratimestampEndOfReadout'][i],format='unix_tai')\n",
    "    \n",
    "    azel = await efd_client.select_time_series(\"lsst.sal.ATMCS.mount_AzEl_Encoders\", \n",
    "                                               [\"elevationCalculatedAngle99\", \"azimuthCalculatedAngle99\"], t1, t2)\n",
    "    # mount reporting incorrect timestamp for time_series (high frequency data)\n",
    "    azel.index=azel.index+pd.tseries.offsets.DateOffset(seconds=-37)\n",
    "    \n",
    "    rotator = await efd_client.select_time_series(\"lsst.sal.ATMCS.mount_Nasmyth_Encoders\",\n",
    "                                                  [\"nasmyth2CalculatedAngle99\"], t1, t2)\n",
    "    # mount reporting incorrect timestamp for time_series (high frequency data)\n",
    "    rotator.index=rotator.index+pd.tseries.offsets.DateOffset(seconds=-37)\n",
    "\n",
    "    m1_pressure = await efd_client.select_time_series(\"lsst.sal.ATPneumatics.m1AirPressure\",\n",
    "                                                  [\"pressure\"], t1, t2)\n",
    "    \n",
    "    # dimm only publishes every minute or so\n",
    "    dimm = await efd_client.select_time_series(\"lsst.sal.DIMM.logevent_dimmMeasurement\",\n",
    "                                                  [\"fwhm\"], t1- TimeDelta(60., format='sec', scale='tai'), t2+ TimeDelta(60., format='sec', scale='tai'))\n",
    "    \n",
    "    # airmass should come from pointing, but it's the target airmass which doesn't seem to follow\n",
    "    # what the mount position is... \n",
    "#     pointing = await efd_client.select_time_series(\"lsst.sal.ATPtg.currentTargetStatus\",\n",
    "#                                                   [\"airmass\"], t1, t2)\n",
    "    \n",
    "    # want time during long exposure for hexapod position (or basically just not the CWFS data)\n",
    "    t2_hex = Time(df['inFocustimestampEndOfReadout'][i], format='unix_tai')\n",
    "    t1_hex = t1-TimeDelta(df['inFocusExpTime20s'][i], format='sec', scale='tai') # this is subtraction, so before endOfReadout event above\n",
    "    hexapod_vals = await efd_client.select_time_series(\"lsst.sal.ATHexapod.positionStatus\", \n",
    "                                       [\"reportedPosition0\", \"reportedPosition1\", \"reportedPosition2\",\n",
    "                                       \"reportedPosition3\", \"reportedPosition4\", \"reportedPosition5\"], t1_hex , t2_hex)\n",
    "\n",
    "# For offsets we want to find the offsets between the start of the set and the beginning of the in-focus image, but the end works too\n",
    "#     cmd_offset = await efd_client.select_time_series(\"lsst.sal.ATAOS.command_offset\",\n",
    "#                                                  [\"u\", \"v\", \"w\", \"x\", \"y\", \"z\"], offset_start , Time(df['inFocustimestampEndOfReadout'][i], format='unix_tai'))\n",
    "    \n",
    "    # to use the dataframe.between_time(), convert astropy Time object, to numpy time object, to pandas time object, and get the datetime.time\n",
    "#     time1=pd.to_datetime(t1_set.to_datetime()).time()\n",
    "#     time2=pd.to_datetime((Time(df['inFocustimestampEndOfReadout'][i],format='unix_tai')).to_datetime()).time()\n",
    "\n",
    "    df_tmp=pd.DataFrame({'rot_pos':np.mean(rotator['nasmyth2CalculatedAngle99']),\n",
    "                     'el':np.mean(azel['elevationCalculatedAngle99']),\n",
    "                     'az':np.mean(azel['azimuthCalculatedAngle99']),\n",
    "                     'x':hexapod_vals['reportedPosition0'].median(),\n",
    "                     'y':hexapod_vals['reportedPosition1'].median(),\n",
    "                     'z':hexapod_vals['reportedPosition2'].median(),\n",
    "                     'u':hexapod_vals['reportedPosition3'].median(),\n",
    "                     'v':hexapod_vals['reportedPosition4'].median(),\n",
    "                     'w':hexapod_vals['reportedPosition5'].median(),\n",
    "                     'm1': np.mean(m1_pressure['pressure']),\n",
    "                     'airmass': 1.0/np.cos((90-np.mean(azel['elevationCalculatedAngle99']))*np.pi/180), #np.median(pointing['airmass']),\n",
    "                     'seeing': np.mean(dimm['fwhm']),\n",
    "#                      'hexXoffset': cmd_offset['x'].sum(),\n",
    "#                      'hexYoffset': cmd_offset['y'].sum(),\n",
    "#                      'hexUoffset': cmd_offset['u'].sum(),\n",
    "#                      'hexVoffset': cmd_offset['v'].sum(),\n",
    "#                      'hexZoffset': cmd_offset['z'].sum(),\n",
    "                        },\n",
    "                     index=[df.index[i]])\n",
    "    df_offsets=df_offsets.append(df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the two dataframes to create a single one\n",
    "df=df.join(df_offsets, lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"data/\"+date+'_'+test+\"_\"+run+\"_metadata.csv\"\n",
    "df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get M1 mirror data and fit a plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmd = await efd_client.select_time_series(\"lsst.sal.PMD.position\", [\"position0\", \"position1\", \"position2\", \"position3\", \"position5\"], t1_set, t2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file (written using code above)\n",
    "filename=\"data/\"+date+'_'+test+\"_\"+run+\"_metadata.csv\"\n",
    "df3 = pd.read_csv(filename, index_col=0)\n",
    "df3.index=pd.to_datetime(df3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=rendezvous_dataframes(df3, pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position0_offset = (df4.position0[0])\n",
    "position1_offset = (df4.position1[0])\n",
    "position2_offset = (df4.position2[0])\n",
    "position3_offset = (df4.position3[0])\n",
    "position4_offset = (df4.position5[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "arr_len = len(df4.position0)\n",
    "coeff_arr = np.zeros((arr_len,3))\n",
    "theta_arr = np.zeros((arr_len))\n",
    "phi_arr = np.zeros((arr_len))\n",
    "piston_arr = np.zeros((arr_len))\n",
    "for i in np.arange(arr_len):\n",
    "\n",
    "    # X, Y, Z - measured from solidmodel\n",
    "    set2=np.array((  41.0, 468.0, (df4.position2[i]-position2_offset)))\n",
    "    set3=np.array(( 384.0,-269.0, (df4.position3[i]-position3_offset)))\n",
    "    set4=np.array((-425.0,-198.0, (df4.position5[i]-position4_offset)))\n",
    "\n",
    "    # Vector PQ crossed with Vector PR\n",
    "    normal = np.cross(set3-set2,set4-set2) # gives a,b,c\n",
    "    #print(f'normal is {normal}')\n",
    "#     theta_arr[i] = (np.pi/2 + np.arctan2(normal[2],normal[0])) * 206265 # arcsec\n",
    "#     phi_arr[i] = (np.pi/2 + np.arctan2(normal[2],normal[1])) * 206265   # arcsec\n",
    "#     piston_arr[i] = normal[2]\n",
    "    \n",
    "#     => a * (x - x0) + b * (y - y0) + c * (z - z0) = 0.\n",
    "# => a * x - a * x0 + b * y - b * y0 + c * z - c * z0 = 0.\n",
    "# => a * x + b * y + c * z + (- a * x0 - b * y0 - c * z0) = 0. # D is the last terms\n",
    "    D= -normal[0]*set2[0] - normal[1]*set2[1] - normal[2]*set2[2]  # Constant in plane equation\n",
    "    # equation \n",
    "    \n",
    "    phi_from_normal = (np.pi/2+np.arctan2(normal[2], normal[1])) * 206265\n",
    "    theta_from_normal = (np.pi/2+np.arctan2(normal[2], normal[0])) * 206265\n",
    "    # find z at the origin to represent piston\n",
    "    Z_origin = -D/normal[2]\n",
    "    \n",
    "    # Measure rotation about the Y-axis (perpendicular to elevation)\n",
    "    # So this is TIP and should result in motion in azimuth\n",
    "    # get slope by looking at Y=0, X=400\n",
    "    x_pt=400; y_pt=0\n",
    "    #Z_at_x_pt= C[0]*x_pt + C[1]*0.0 + C[2]\n",
    "    Z_at_x_pt= (-D - normal[0]*x_pt - normal[1]*0.0)/normal[2]\n",
    "    theta = np.arctan2(Z_at_x_pt-Z_origin, x_pt) * 206265 # arcsec\n",
    "        \n",
    "    # Measure rotation about the X-axis (aligned to elevation)\n",
    "    # this is TILT and should result in motion in elevation\n",
    "    # get slope by looking at Y=0, X=400    \n",
    "    x_pt=0; y_pt=400\n",
    "    Z_at_y_pt= (-D - normal[0]*x_pt - normal[1]*y_pt)/normal[2]\n",
    "    phi = np.arctan2(Z_at_y_pt-Z_origin, y_pt) * 206265 # arcsec\n",
    "\n",
    "    theta_arr[i] = theta # arcsec\n",
    "    phi_arr[i] = phi    # arcsec\n",
    "    piston_arr[i] = Z_origin\n",
    "    \n",
    "    print(f'theta_from_normal is {theta_from_normal:0.2f}, phi_from_normal is {phi_from_normal:0.2f}')\n",
    "    print(f'theta_arr is {theta_arr[i]:0.2f} [arcsec], phi_arr is {phi_arr[i]:0.2f} [arcsec]')\n",
    "#     if i == 1:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['m1_tip']=theta_arr\n",
    "df4['m1_tilt']=phi_arr\n",
    "df4['m1_piston']=piston_arr\n",
    "\n",
    "df4['m1_y_pos']=(df4.position0-position0_offset)*np.cos(10*np.pi/180)\n",
    "df4['m1_x_pos']=(df4.position1-position1_offset)*np.cos(10*np.pi/180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to CSV file\n",
    "filename=\"data/\"+date+'_'+test+\"_\"+run+\"_data_with_WFE_and_m1_pos.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the M1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file (written using code above)\n",
    "filename=\"data/\"+date+'_'+test+\"_\"+run+\"_data_with_WFE_and_m1_pos.csv\"\n",
    "df5 = pd.read_csv(filename, index_col=0)\n",
    "df5.index=pd.to_datetime(df5.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_height=5\n",
    "fig_width=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nwide=3; nhigh=3\n",
    "fig, (row1,row2,row3) = plt.subplots(nhigh, nwide, figsize=(nwide+fig_width, nhigh*fig_height))\n",
    "fig.suptitle('Rows are')\n",
    "xvals = (df4.m1_x_pos) # um\n",
    "yvals = df4.el\n",
    "\n",
    "row1[0].plot(xvals, yvals, 'o-')\n",
    "row1[0].set_ylabel('Elevation [deg]')\n",
    "row1[0].set_xlabel('M1 X-position [mm]')\n",
    "\n",
    "xvals=df4.y\n",
    "row1[1].plot(xvals,yvals, '.-')\n",
    "row1[1].set_xlabel('Hexapod Y-position [mm]')\n",
    "\n",
    "\n",
    "xvals = (df4.m1_tip) # um\n",
    "row1[2].plot(xvals, yvals, 'o-')\n",
    "row1[2].set_ylabel('Elevation [deg]')\n",
    "row1[2].set_xlabel('M1 tip [arcsec]')\n",
    "\n",
    "\n",
    "xvals = (df4.m1_y_pos) # mm\n",
    "row2[0].plot(xvals, yvals, 'o-')\n",
    "row2[0].set_ylabel('Elevation [deg]')\n",
    "row2[0].set_xlabel('M1 X-position [mm]')\n",
    "\n",
    "xvals=df4.x\n",
    "row2[1].plot(xvals,yvals, '.-')\n",
    "row2[1].set_xlabel('Hexapod X-position [mm]')\n",
    "\n",
    "xvals = (df4.m1_tilt) # um\n",
    "row2[2].plot(xvals, yvals, 'o-')\n",
    "row2[2].set_ylabel('Elevation [deg]')\n",
    "row2[2].set_xlabel('M1 tilt [arcsec]')\n",
    "\n",
    "xvals = (df4.m1_piston) # mm\n",
    "row3[0].plot(xvals, yvals, 'o-')\n",
    "row3[0].set_ylabel('Elevation [deg]')\n",
    "row3[0].set_xlabel('M1 Z-position [mm]')\n",
    "\n",
    "xvals=df4.z\n",
    "row3[1].plot(xvals,yvals, '.-')\n",
    "row3[1].set_xlabel('Hexapod Z-position [mm]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Stellar Movement and PSF info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.pipe.tasks.characterizeImage import CharacterizeImageTask\n",
    "from lsst.meas.algorithms.installGaussianPsf import InstallGaussianPsfConfig\n",
    "from lsst.pex.exceptions import InvalidParameterError\n",
    "def measurePsf(exp):\n",
    "    PLATESCALE = 0.095695\n",
    "\n",
    "    imCharConfig = CharacterizeImageTask.ConfigClass()\n",
    "    imCharConfig.doMeasurePsf = True\n",
    "    imCharConfig.useSimplePsf = True\n",
    "    \n",
    "    imCharConfig.doApCorr = False\n",
    "    imCharConfig.doDeblend = False\n",
    "    \n",
    "    installConfig = InstallGaussianPsfConfig()\n",
    "    exp.setPsf(None)  # if not set to none, fwhm max para is ignored\n",
    "    installConfig.fwhm = 25\n",
    "    installConfig.width = 61\n",
    "    \n",
    "    imCharConfig.installSimplePsf = installConfig    \n",
    "    \n",
    "    imCharConfig.detection.includeThresholdMultiplier = 5\n",
    "\n",
    "    imCharConfig.measurePsf.starSelector['objectSize'].doFluxLimit = True\n",
    "    imCharConfig.measurePsf.starSelector['objectSize'].fluxMin = 12500.0\n",
    "    imCharConfig.measurePsf.starSelector['objectSize'].fluxMax = 0.0\n",
    "    imCharConfig.measurePsf.starSelector['objectSize'].doSignalToNoiseLimit = False\n",
    "    imCharConfig.measurePsf.starSelector['objectSize'].signalToNoiseMin = 20.0\n",
    "    imCharConfig.measurePsf.starSelector['objectSize'].signalToNoiseMax = 0.0\n",
    "    imCharConfig.measurePsf.starSelector['objectSize'].widthMin = 0.0\n",
    "    imCharConfig.measurePsf.starSelector['objectSize'].widthMax = 80.0  # default 10\n",
    "    imCharConfig.measurePsf.starSelector['objectSize'].sourceFluxField = \"base_GaussianFlux_instFlux\"\n",
    "    imCharConfig.measurePsf.starSelector['objectSize'].widthStdAllowed = 0.15 # 0.15 default\n",
    "    imCharConfig.measurePsf.starSelector['objectSize'].nSigmaClip = 2.0\n",
    "    \n",
    "    \n",
    "    imCharConfig.background.binSize = 2000\n",
    "    imCharConfig.background.approxOrderX = 2\n",
    "    imCharConfig.measurePsf.psfDeterminer['psfex'].spatialOrder = 1\n",
    "\n",
    "    imCharConfig.detection.background = imCharConfig.background\n",
    "    \n",
    "    imCharTask = CharacterizeImageTask(config=imCharConfig)\n",
    "\n",
    "    result = imCharTask.run(exp)\n",
    "\n",
    "    psf = exp.getPsf()\n",
    "    ixx = psf.computeShape(exp.getBBox().getCenter()).getIxx()\n",
    "    iyy = psf.computeShape(exp.getBBox().getCenter()).getIyy()\n",
    "    psfShape = psf.computeShape(exp.getBBox().getCenter()).getDeterminantRadius()\n",
    "    \n",
    "    fwhmX = np.sqrt(ixx)*2.355*PLATESCALE\n",
    "    fwhmY = np.sqrt(iyy)*2.355*PLATESCALE\n",
    "    \n",
    "    overallFwhm = psfShape * 2.355 * PLATESCALE\n",
    "    print(f\"Psf shape from imChar task (x,y) = ({fwhmX:.3f}, {fwhmY:.3f}) FWHM arcsec\")\n",
    "    return fwhmX, fwhmY, overallFwhm, psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.pipe.tasks.quickFrameMeasurement import QuickFrameMeasurementTask\n",
    "from lsst.ts.observing.utilities.auxtel.latiss.utils import parse_obs_id,calculate_xy_offsets\n",
    "from lsst.ts.observing.utilities.auxtel.latiss.getters import get_image\n",
    "from astropy import units as u\n",
    "from lsst.geom import PointD\n",
    "qm_config = QuickFrameMeasurementTask.ConfigClass()\n",
    "qm = QuickFrameMeasurementTask(config=qm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightest_source_centroid = []\n",
    "fwhmX_arr=[]; fwhmY_arr=[]; overallFwhm_arr=[]\n",
    "\n",
    "for image_name in df5.inFocus20s:\n",
    "    print(f'Processing image {image_name}')\n",
    "    if image_name is None:\n",
    "        continue\n",
    "    _, _, day_obs, seq_num = image_name.split(\"_\")\n",
    "    day_obs = int(f\"{day_obs[0:4]}{day_obs[4:6]}{day_obs[6:8]}\")\n",
    "    exp = await get_image(\n",
    "            dict(day_obs=day_obs, seq_num=int(seq_num), detector=0),\n",
    "            datapath=\"/readonly/repo/main/\",\n",
    "            timeout=10,\n",
    "            runBestEffortIsr=True,\n",
    "        )\n",
    "    result = qm.run(exp)\n",
    "    brightest_source_centroid.append(result)\n",
    "    try:\n",
    "        fwhmX, fwhmY, overallFwhm, psf = measurePsf(exp)\n",
    "        fwhmX_arr.append(fwhmX)\n",
    "        fwhmY_arr.append(fwhmY)\n",
    "        overallFwhm_arr.append(overallFwhm)\n",
    "    except InvalidParameterError as e:\n",
    "        print('Caught the InvalidParameterError, marking values as NaNs')\n",
    "        print(f'error is {e}')\n",
    "        fwhmX_arr.append(np.nan)\n",
    "        fwhmY_arr.append(np.nan)\n",
    "        overallFwhm_arr.append(np.nan) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate alt/az motions in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix(angle):\n",
    "    \"\"\"Rotation matrix.\n",
    "    \"\"\"\n",
    "    return np.array(\n",
    "        [\n",
    "            [np.cos(np.radians(angle)), -np.sin(np.radians(angle)), 0.0],\n",
    "            [np.sin(np.radians(angle)), np.cos(np.radians(angle)), 0.0],\n",
    "            [0.0, 0.0, 1.0],\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_arr = np.array(df4.el) - np.array(df4.az) + 90.0 # degrees\n",
    "\n",
    "#azel_correction = np.zeros((2, len(calc_data.xcentroid)))\n",
    "azel_correction = np.zeros((2, len(brightest_source_centroid)))\n",
    "im_centroid = np.zeros((2, len(brightest_source_centroid)))\n",
    "reference = PointD(brightest_source_centroid[0].brightestObjCentroid)\n",
    "medianXxYy = np.zeros((2, len(brightest_source_centroid)))\n",
    "\n",
    "for i, source_xy in enumerate(brightest_source_centroid):\n",
    "    dx_arcsec, dy_arcsec = calculate_xy_offsets(\n",
    "        PointD(\n",
    "            source_xy.brightestObjCentroid[0],\n",
    "            source_xy.brightestObjCentroid[1]\n",
    "        ), \n",
    "        reference)\n",
    "\n",
    "    # We are using rotator 2 so we must apply a negative sign on the x-axis offset.\n",
    "    # The equation bellow return offset in elevation/azimuth.\n",
    "    elaz_offset = np.matmul((-dx_arcsec, dy_arcsec, 0.), rotation_matrix(angle_arr[i]))*u.arcsec\n",
    "    azel_correction[:,i] = np.array((elaz_offset[0].value, elaz_offset[1].value))\n",
    "    im_centroid[:,i] = np.array((source_xy.brightestObjCentroid[0], source_xy.brightestObjCentroid[1]))\n",
    "    medianXxYy[:,i] = np.array((source_xy.medianXxYy[0], source_xy.medianXxYy[1]))\n",
    "    \n",
    "    print(elaz_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['xcentroid']=im_centroid[0,:]\n",
    "df5['ycentroid']=im_centroid[1,:]\n",
    "\n",
    "df5['azShift']=azel_correction[0,:]\n",
    "df5['elShift']=azel_correction[1,:]\n",
    "\n",
    "df5['medianXx']=medianXxYy[0,:]\n",
    "df5['medianYy']=medianXxYy[1,:]\n",
    "\n",
    "df5['medianXx']=medianXxYy[0,:]\n",
    "df5['medianYy']=medianXxYy[1,:]\n",
    "\n",
    "df5['psf_fwhmx']=fwhmX_arr\n",
    "df5['psf_fwhmy']=fwhmY_arr\n",
    "df5['psf_fwhm_overall']=overallFwhm_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to CSV file\n",
    "filename=\"data/\"+date+'_'+test+\"_\"+run+\"_data_with_WFE_m1Pos_centroids.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab the seeing from the DIMM files\n",
    "#### When the dimm CSC isn't up sftp them from the preat files on the dimm machine (/mnt/dimm/log/dimm_tool/out/YYMMDD-preat.stm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import datetime\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "files=['210816-preat.stm','210817-preat.stm','210818-preat.stm']\n",
    "for f in files:\n",
    "    with open(f,'r') as csvfile:\n",
    "        plots = csv.reader(\"data/\"+csvfile, delimiter=' ')\n",
    "        for i,row in enumerate(plots):\n",
    "            # we only want the A rows\n",
    "            #print(row)\n",
    "            if row[0] == 'A':\n",
    "        #        print(row[2],row[8])\n",
    "                timestamp=row[1]+\" \"+row[2]\n",
    "                timestampobj=datetime.datetime.strptime(timestamp,'%Y-%m-%d %H:%M:%S')\n",
    "                try:\n",
    "                    val = 2.0e7*float(row[8])**0.6\n",
    "                except ValueError:\n",
    "                    print(f'Caught a bad value in file {f} row {i}. Skipping row.')\n",
    "                    continue\n",
    "                x.append(timestampobj)\n",
    "                y.append(val)\n",
    "        #        print(x,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x,y, label='From common mode motion')\n",
    "# plt.rcParams['figure.figsize'] = [14, 8]\n",
    "# plt.gcf().autofmt_xdate()\n",
    "# myFmt = mdates.DateFormatter('%H:%M')\n",
    "# plt.gca().xaxis.set_major_formatter(myFmt)\n",
    "# plt.xlabel('UT Time')\n",
    "# plt.ylabel('Calculated DIMM Seeing (arcsec)')\n",
    "# plt.title('DIMM Output UT 2019-04-01')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe for the seeing\n",
    "d = {'seeing' : pd.Series(y, index=x),}\n",
    "df_dimm = pd.DataFrame(d)\n",
    "# smooth by over 3 minutes\n",
    "width=3\n",
    "width=pd.Timedelta(value=2, unit='minutes')\n",
    "df_dimm['mov_avg'] = df_dimm['seeing'].rolling(width).median()\n",
    "df_dimm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y, label='From common mode motion')\n",
    "plt.rcParams['figure.figsize'] = [14, 8]\n",
    "plt.gcf().autofmt_xdate()\n",
    "myFmt = mdates.DateFormatter('%H:%M')\n",
    "plt.gca().xaxis.set_major_formatter(myFmt)\n",
    "plt.xlabel('UT Time')\n",
    "plt.ylabel('Calculated DIMM Seeing (arcsec)')\n",
    "plt.title('DIMM Output UT 2021-08-18')\n",
    "# plt.plot(df_dimm.index,df_dimm.mov_avg,label=f'Median boxcar width= {width}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=rendezvous_dataframes(df5, df_dimm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to CSV file\n",
    "filename=\"data/\"+date+'_'+test+\"_\"+run+\"_data_with_WFE_m1Pos_centroids_dimm.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nwide=3; nhigh=3\n",
    "fig, (row1,row2,row3) = plt.subplots(nhigh, nwide, figsize=(nwide+fig_width, nhigh*fig_height))\n",
    "fig.suptitle('Rows are')\n",
    "df_plot=df6\n",
    "xvals = (df_plot.m1_x_pos) # um\n",
    "yvals = df_plot.el\n",
    "\n",
    "row1[0].plot(xvals, yvals, 'o-')\n",
    "row1[0].set_ylabel('Elevation [deg]')\n",
    "row1[0].set_xlabel('M1 X-position [mm]')\n",
    "\n",
    "xvals=df_plot.y\n",
    "row1[1].plot(xvals,yvals, '.-')\n",
    "row1[1].set_xlabel('Hexapod Y-position [mm]')\n",
    "\n",
    "xvals = (df_plot.m1_tip) # um   - Tip should mean ~azimuth motion\n",
    "row1[2].plot(xvals, yvals, 'o-')\n",
    "row1[2].set_xlabel('M1 tip [arcsec]')\n",
    "\n",
    "xvals = (df_plot.m1_y_pos) # mm\n",
    "row2[0].plot(xvals, yvals, 'o-')\n",
    "row2[0].set_ylabel('Elevation [deg]')\n",
    "row2[0].set_xlabel('M1 X-position [mm]')\n",
    "\n",
    "xvals=df_plot.x\n",
    "row2[1].plot(xvals,yvals, '.-')\n",
    "row2[1].set_xlabel('Hexapod X-position [mm]')\n",
    "\n",
    "xvals = (df_plot.m1_tilt) # um\n",
    "row2[2].plot(xvals, yvals, 'o-')\n",
    "row2[2].set_xlabel('M1 tilt [arcsec]')\n",
    "\n",
    "xvals = (df_plot.m1_piston) # mm\n",
    "row3[0].plot(xvals, yvals, 'o-')\n",
    "row3[0].set_ylabel('Elevation [deg]')\n",
    "row3[0].set_xlabel('M1 Z-position [mm]')\n",
    "\n",
    "xvals=df_plot.z\n",
    "row3[1].plot(xvals,yvals, '.-')\n",
    "row3[1].set_xlabel('Hexapod Z-position [mm]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nwide=3; nhigh=1\n",
    "fig, (row1) = plt.subplots(nhigh, nwide, figsize=(nwide+fig_width, nhigh*fig_height))\n",
    "fig.suptitle('Rows are')\n",
    "df_plot=df6\n",
    "yvals = df_plot.el\n",
    "\n",
    "xvals = df_plot.medianXx # um\n",
    "row1[0].plot(xvals, yvals, 'o-')\n",
    "row1[0].set_ylabel('Elevation [deg]')\n",
    "row1[0].set_xlabel('X-FWHM [arcsec]')\n",
    "\n",
    "xvals=df_plot.medianYy\n",
    "row1[1].plot(xvals,yvals, '.-')\n",
    "row1[1].set_xlabel('Y-FWHM [arcsec]')\n",
    "\n",
    "xvals=(df_plot.medianYy+df_plot.medianXx)/2\n",
    "row1[2].plot(xvals,yvals, '.-')\n",
    "row1[2].set_xlabel('FWHM [arcsec]')\n",
    "\n",
    "xvals = df_plot.psf_fwhmx # um\n",
    "row1[0].plot(xvals, yvals, 'o-')\n",
    "row1[0].set_ylabel('Elevation [deg]')\n",
    "row1[0].set_xlabel('X-FWHM [arcsec]')\n",
    "\n",
    "xvals=df_plot.psf_fwhmy\n",
    "row1[1].plot(xvals,yvals, '.-')\n",
    "row1[1].set_xlabel('Y-FWHM [arcsec]')\n",
    "\n",
    "xvals=df_plot.psf_fwhm_overall\n",
    "row1[2].plot(xvals,yvals, '.-')\n",
    "row1[2].set_xlabel('FWHM [arcsec]')\n",
    "\n",
    "xvals=df_plot.seeing\n",
    "row1[2].plot(xvals,yvals, '.-')\n",
    "row1[2].set_xlabel('FWHM [arcsec]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = ['initial','iter2']\n",
    "sym= ['.-','x-','s-']\n",
    "color=['red','blue','green']\n",
    "df={}\n",
    "\n",
    "fig_height=5\n",
    "fig_width=15\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import colors\n",
    "\n",
    "nwide=3; nhigh=2\n",
    "fig, (row1,row2) = plt.subplots(nhigh, nwide, figsize=(nwide+fig_width, nhigh*fig_height))\n",
    "fig.suptitle('Row1 is QM data, Row2 is from psfEx')\n",
    "\n",
    "for i,r in enumerate(runs):\n",
    "    filename=\"data/\"+date+'_'+test+\"_\"+r+\"_data_with_WFE_m1Pos_centroids_dimm.csv\"\n",
    "    df[r] = pd.read_csv(filename, index_col=0)\n",
    "    print(filename)\n",
    "    df[r].index=pd.to_datetime(df[r].index)\n",
    "    yvals = df[r].el\n",
    "\n",
    "    xvals = df[r].medianXx # um\n",
    "    row1[0].plot(xvals, yvals, 'o-')\n",
    "    row1[0].set_ylabel('Elevation [deg]')\n",
    "    row1[0].set_xlabel('X-FWHM [arcsec]')\n",
    "\n",
    "    xvals=df[r].medianYy\n",
    "    row1[1].plot(xvals,yvals, '.-')\n",
    "    row1[1].set_xlabel('Y-FWHM [arcsec]')\n",
    "\n",
    "    xvals=(df[r].medianYy+df[r].medianXx)/2.0\n",
    "    row1[2].plot(xvals,yvals, '.-',color=color[i])\n",
    "    row1[2].set_xlabel('FWHM [arcsec]')\n",
    "    \n",
    "    xvals=df[r].seeing\n",
    "    row1[2].plot(xvals,yvals, '.--', color=color[i], label='seeing')\n",
    "    row1[2].set_xlabel('FWHM [arcsec]')\n",
    "    row1[2].legend()\n",
    "\n",
    "    xvals = df[r].psf_fwhmx # um\n",
    "    row2[0].plot(xvals, yvals, 'o-')\n",
    "    row2[0].set_ylabel('Elevation [deg]')\n",
    "    row2[0].set_xlabel('X-FWHM [arcsec]')\n",
    "\n",
    "    xvals=df[r].psf_fwhmy\n",
    "    row2[1].plot(xvals,yvals, '.-')\n",
    "    row2[1].set_xlabel('Y-FWHM [arcsec]')\n",
    "\n",
    "    xvals=df[r].psf_fwhm_overall\n",
    "    row2[2].plot(xvals,yvals, '.-',color=color[i])\n",
    "    row2[2].set_xlabel('FWHM [arcsec]')\n",
    "    \n",
    "    xvals=df[r].seeing\n",
    "    row2[2].plot(xvals,yvals, '.--', color=color[i], label='seeing')\n",
    "    row2[2].set_xlim(0.7,2.4)\n",
    "    row2[2].set_xlabel('FWHM [arcsec]')\n",
    "    row2[2].set_ylabel('Elevation [deg]')\n",
    "    row2[2].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = ['initial','iter2']\n",
    "sym= ['.-','x-','s-']\n",
    "color=['red','blue','green']\n",
    "df={}\n",
    "\n",
    "fig_height=10\n",
    "fig_width=10\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import colors\n",
    "\n",
    "nwide=1; nhigh=1\n",
    "fig,row1 = plt.subplots(nhigh, nwide, figsize=(nwide+fig_width, nhigh*fig_height))\n",
    "fig.suptitle('Data is from psfEx')\n",
    "\n",
    "for i,r in enumerate(runs):\n",
    "    filename=\"data/\"+date+'_'+test+\"_\"+r+\"_data_with_WFE_m1Pos_centroids_dimm.csv\"\n",
    "    df[r] = pd.read_csv(filename, index_col=0)\n",
    "    print(filename)\n",
    "    df[r].index=pd.to_datetime(df[r].index)\n",
    "    yvals = df[r].el\n",
    "\n",
    "    xvals=df[r].psf_fwhm_overall-df[r].seeing\n",
    "    row1.plot(xvals,yvals, '.--', color=color[i], label=f'{r} sequence')\n",
    "#     row2[2].set_xlim(0.7,2.4)\n",
    "    row1.set_xlabel('(Measured FWHM - Seeing) [arcsec]')\n",
    "    row1.set_ylabel('Elevation [deg]')\n",
    "    row1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.daf.butler as dafButler\n",
    "butler = dafButler.Butler('/readonly/repo/main', instrument='LATISS', collections='LATISS/raw/all')\n",
    "dataId = {'day_obs': 20210907, 'seq_num': 375, 'detector': 0} \n",
    "dataId = {'day_obs': 20210909, 'seq_num': 375, 'detector': 0} \n",
    "raw = butler.get('raw', dataId=dataId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
