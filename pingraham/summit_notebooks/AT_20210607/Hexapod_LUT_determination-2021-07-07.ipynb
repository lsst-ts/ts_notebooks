{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to determine if the image motion seen during observations is coming from M1\n",
    "## This is for data taken on 2021-07-07. CWFS data was taken and corrections were performed at multiple elevations to derive the hexapod LUT.\n",
    "## So the calculated corrections are offsets from the LUTs, which are in-use. \n",
    "### It first finds the pairs of CWFS images in the EFD\n",
    "### It then fits the data a reports the zernikes\n",
    "### It also plots the image motion error as a function of elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio \n",
    "import matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "from astropy.time import Time, TimeDelta\n",
    "\n",
    "from lsst_efd_client import EfdClient, resample, rendezvous_dataframes\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#efd_client = EfdClient('summit_efd')\n",
    "efd_client = EfdClient('ldf_stable_efd') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find CWFS pairs\n",
    "Query for all the `endReadout` events on the timespan of the night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date='20210707'\n",
    "test='hex_LUT_determ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='iter1'\n",
    "\n",
    "if run == 'iter1':\n",
    "    # mitutoyos dropped out\n",
    "    # times from when images were taken, \n",
    "    t1_set = Time(\"2021-07-08T00:01:00\", format='isot', scale='tai')\n",
    "    t2_set = Time(\"2021-07-08T02:00:44\", format='isot', scale='tai')\n",
    "    start_log_msg = '[2021-07-08_Repeat_Focus_Test_START]'\n",
    "    finish_log_msg = '[2021-07-08_Repeat_Focus_Test_END]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_readout = await efd_client.select_time_series(\"lsst.sal.ATCamera.logevent_endReadout\", \n",
    "                                           [\"imageName\", \"requestedExposureTime\", \"additionalKeys\",\n",
    "                                            \"additionalValues\",\"timestampAcquisitionStart\",\"timestampEndOfReadout\"], t1_set, t2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base0 = await efd_client.select_time_series(\"lsst.sal.Script.logevent_logMessage\", \n",
    "                                           [\"message\",\"level\"], t1_set, t2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(base0.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the start/end sequences and trim the bad ones\n",
    "# base = base0[(base0.message.str.find(start_log_msg) != -1) | (base0.message.str.find(finish_log_msg) != -1)]\n",
    "base=base0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop false starts\n",
    "if run == 'initial':\n",
    "    time_reg = '2021-07-09 02:41:02.488000+00:00'\n",
    "    ind=base.index.get_loc(time_reg, method='nearest')\n",
    "    base.drop(base.index[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now match each entry. For each `i` item with `intra` in the name, there must be an `i+1` with `extra` otherwise it is not a pair. \n",
    "A pair also has the same groupID\n",
    "The image before the pair is an in-focus image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_images = []\n",
    "extra_images = []\n",
    "in_focus_images = []\n",
    "intra_times = []\n",
    "extra_times = []\n",
    "in_focus_times = []\n",
    "intra_exptimes = []\n",
    "extra_exptimes = []\n",
    "in_focus_exptimes = []\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "npairs = 0\n",
    "nmiss = 0\n",
    "\n",
    "while i < len(end_readout)-1:\n",
    "    intra = end_readout['imageName'][i]\n",
    "    extra = end_readout['imageName'][i+1]\n",
    "    in_focus = end_readout['imageName'][i+2]\n",
    "    \n",
    "    #skip known bad files\n",
    "    if intra == 'AT_O_20200218_000179' and extra == 'AT_O_20200218_000180':\n",
    "        i+=2\n",
    "        continue\n",
    "    # this is horrible, but looks for sequence as it was taken\n",
    "    # CWFS frames, then 2s in focus object\n",
    "    # finds the in-focus image by seeing if an OBJECT was taken right before the pair\n",
    "    # using a colon to separate values causes issues because there are colons in the timestamp!\n",
    "    group_id_cwfs_in=(end_readout.additionalValues[i])[0:25]\n",
    "    imgtype_cwfs_in=(end_readout.additionalValues[i])[-6:]\n",
    "    group_id_cwfs_out=(end_readout.additionalValues[i+1])[0:25] \n",
    "    imgtype_cwfs_out=(end_readout.additionalValues[i+1])[-6:]\n",
    "    group_id_5s=(end_readout.additionalValues[i+2])[0:25]\n",
    "    imgtype_5s=(end_readout.additionalValues[i+2])[-6:]\n",
    "\n",
    "    if ((group_id_cwfs_in == group_id_cwfs_out) and \n",
    "        (imgtype_5s == 'OBJECT') and\n",
    "       imgtype_cwfs_in == 'NGTEST'):\n",
    "        \n",
    "        print(f\"Got a pair: {intra} x {extra}, with in-focus of {in_focus}\")\n",
    "        df_tmp=pd.DataFrame({'inFocus5s':end_readout['imageName'][i+2],\n",
    "                             'intra':end_readout['imageName'][i],\n",
    "                             'extra':end_readout['imageName'][i+1],\n",
    "                             # Need times during cwfs for telescope position\n",
    "                             'inFocusExpTime':end_readout['requestedExposureTime'][i+2],\n",
    "                             'inFocustimestampEndOfReadout':end_readout['timestampEndOfReadout'][i+2],\n",
    "                             'intraExtratimestampAcquisitionStart':end_readout['timestampAcquisitionStart'][i],\n",
    "                             'intraExtratimestampEndOfReadout':end_readout['timestampEndOfReadout'][i+1],\n",
    "                            }, index=[end_readout.index[i+2]])\n",
    "        df=df.append(df_tmp)\n",
    "        i+=2\n",
    "        npairs+=1\n",
    "    else:\n",
    "#         print(f\"No Match: {intra} x {extra}\")\n",
    "        nmiss+=1\n",
    "        i+=1\n",
    "\n",
    "print(f\"Got {npairs} pairs and {nmiss} misses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe with new values of interest and we'll join them post-facto\n",
    "df_offsets=pd.DataFrame()\n",
    "# Populate the data structure from the pairs found above\n",
    "for i in range(len(df.index)):\n",
    "    \n",
    "    # Determine time stamps for searching for metadata\n",
    "    # include ability to correct for TAI if required, but set to zero for the moment\n",
    "\n",
    "#    t1 = Time(in_focus_times[i], scale='tai') - TimeDelta(in_focus_exptimes[i], format='sec', scale='tai')\n",
    "#    t2 = Time(extra_times[i], scale='tai') - TimeDelta(2., format='sec', scale='tai')\n",
    "    \n",
    "    # want time during CWFS sensing for telescope position\n",
    "    t1 = Time(df['intraExtratimestampAcquisitionStart'][i], format='unix_tai')\n",
    "    t2 = Time(df['intraExtratimestampEndOfReadout'][i],format='unix_tai')\n",
    "    \n",
    "    azel = await efd_client.select_time_series(\"lsst.sal.ATMCS.mount_AzEl_Encoders\", \n",
    "                                               [\"elevationCalculatedAngle99\", \"azimuthCalculatedAngle99\"], t1, t2)\n",
    "    # mount reporting incorrect timestamp\n",
    "    azel.index=azel.index+pd.tseries.offsets.DateOffset(seconds=-37)\n",
    "    \n",
    "    rotator = await efd_client.select_time_series(\"lsst.sal.ATMCS.mount_Nasmyth_Encoders\",\n",
    "                                                  [\"nasmyth2CalculatedAngle99\"], t1, t2)\n",
    "    # mount reporting incorrect timestamp\n",
    "    rotator.index=rotator.index+pd.tseries.offsets.DateOffset(seconds=-37)\n",
    "\n",
    "    m1_pressure = await efd_client.select_time_series(\"lsst.sal.ATPneumatics.m1AirPressure\",\n",
    "                                                  [\"pressure\"], t1, t2)\n",
    "    # mount reporting incorrect timestamp\n",
    "    m1_pressure.index=m1_pressure.index+pd.tseries.offsets.DateOffset(seconds=-37)\n",
    "    \n",
    "    # want time during long exposure for hexapod position (or basically just not the CWFS data)\n",
    "    t2_hex = Time(df['inFocustimestampEndOfReadout'][i], format='unix_tai')\n",
    "    t1_hex = t1-TimeDelta(df['inFocusExpTime'][i], format='sec', scale='tai') # this is subtraction, so before endOfReadout event above\n",
    "    hexapod_vals = await efd_client.select_time_series(\"lsst.sal.ATHexapod.positionStatus\", \n",
    "                                       [\"reportedPosition0\", \"reportedPosition1\", \"reportedPosition2\",\n",
    "                                       \"reportedPosition3\", \"reportedPosition4\", \"reportedPosition5\"], t1_hex , t2_hex)\n",
    "\n",
    "# For offsets we want to find the offsets between the start of the set and the beginning of the in-focus image, but the end works too\n",
    "#     cmd_offset = await efd_client.select_time_series(\"lsst.sal.ATAOS.command_offset\",\n",
    "#                                                  [\"u\", \"v\", \"w\", \"x\", \"y\", \"z\"], offset_start , Time(df['inFocustimestampEndOfReadout'][i], format='unix_tai'))\n",
    "    \n",
    "    # to use the dataframe.between_time(), convert astropy Time object, to numpy time object, to pandas time object, and get the datetime.time\n",
    "#     time1=pd.to_datetime(t1_set.to_datetime()).time()\n",
    "#     time2=pd.to_datetime((Time(df['inFocustimestampEndOfReadout'][i],format='unix_tai')).to_datetime()).time()\n",
    "\n",
    "    df_tmp=pd.DataFrame({'rot_pos':np.mean(rotator['nasmyth2CalculatedAngle99']),\n",
    "                     'el':np.mean(azel['elevationCalculatedAngle99']),\n",
    "                     'az':np.mean(azel['azimuthCalculatedAngle99']),\n",
    "                     'x':hexapod_vals['reportedPosition0'].median(),\n",
    "                     'y':hexapod_vals['reportedPosition1'].median(),\n",
    "                     'z':hexapod_vals['reportedPosition2'].median(),\n",
    "                     'u':hexapod_vals['reportedPosition3'].median(),\n",
    "                     'v':hexapod_vals['reportedPosition4'].median(),\n",
    "                     'w':hexapod_vals['reportedPosition5'].median(),\n",
    "                     'm1': np.mean(m1_pressure['pressure']),\n",
    "#                      'hexXoffset': cmd_offset['x'].sum(),\n",
    "#                      'hexYoffset': cmd_offset['y'].sum(),\n",
    "#                      'hexUoffset': cmd_offset['u'].sum(),\n",
    "#                      'hexVoffset': cmd_offset['v'].sum(),\n",
    "#                      'hexZoffset': cmd_offset['z'].sum(),\n",
    "                        },\n",
    "                     index=[df.index[i]])\n",
    "    df_offsets=df_offsets.append(df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the two dataframes to create a single one\n",
    "df=df.join(df_offsets, lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.loc[df.index[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = rendezvous_dataframes(end_readout, cmd_offset, direction='backward', tolerance=pd.Timedelta(days=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"data/\"+date+'_'+test+\"_\"+run+\"_metadata.csv\"\n",
    "df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now reduce the data for each pair to get the zernikes from fitting\n",
    "#### You can start here if the top bit has already run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atcs_get_bore_sight_angle(elevation_angle, nasmyth_angle):\n",
    "    # modified from atcs.py\n",
    "    # instrument on nasymth2, so\n",
    "    parity_x = -1\n",
    "    bore_sight_angle = elevation_angle + parity_x * nasmyth_angle + 90.0\n",
    "    return bore_sight_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import asyncio\n",
    "import logging\n",
    "import numpy as np\n",
    "from lsst.ts.externalscripts.auxtel.latiss_cwfs_align import LatissCWFSAlign\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file (written using code above)\n",
    "filename=\"data/\"+date+'_'+test+\"_\"+run+\"_metadata.csv\"\n",
    "df2 = pd.read_csv(filename, index_col=0)\n",
    "df2.index=pd.to_datetime(df2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all the zernike terms from the fitting\n",
    "# this creates columns of NaNs and the loop below populates them\n",
    "df2[['zern_defocus_nm', 'zern_astig_oblique_nm','zern_astig_vertical_nm',\n",
    "    'zern_coma_vertical_nm', 'zern_coma_horizontal_nm',\n",
    "    'zern_trefoil_vertical_nm', 'zern_trefoil_oblique_nm','zern_spherical_nm' ]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this just needs to be set, but is not actually used\n",
    "os.environ['LSST_DDS_DOMAIN'] = 'junk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignment script needs to have remotes set to False! Otherwise it'll try to command the hexapod!\n",
    "script = LatissCWFSAlign(index=1, remotes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the location of the butler repo\n",
    "script.dataPath='/project/shared/auxTel/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visitID_from_filename(filename):\n",
    "    # Expects AT_O_20200218_000167.fits\n",
    "    # parse out visitID from filename - this is highly annoying\n",
    "    tmp=filename.split('_')\n",
    "    prefix=tmp[2] # dayobs without the dashes\n",
    "\n",
    "    # Don't remember why I used int here... whitespace? \n",
    "    # surely fixable but bigger fish.\n",
    "    suffix='{:05d}'.format(int(tmp[3].split('.')[0])) # SEQNUM, but need to trim extra 0 in obsid\n",
    "    visitID = int((prefix+suffix))\n",
    "    #print(visitID)\n",
    "    return visitID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin images when performing fits?\n",
    "script.binning=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(df2)):\n",
    "    # see tstn-015 and example notebook on running latiss_align_cwfs script\n",
    "    script.intra_visit_id = get_visitID_from_filename(df2['intra'].iloc[n])\n",
    "    script.extra_visit_id = get_visitID_from_filename(df2['extra'].iloc[n])\n",
    "    script.angle = 90-atcs_get_bore_sight_angle(df2['el'].iloc[n], df2['rot_pos'].iloc[n])\n",
    "\n",
    "    start_time=time.time()\n",
    "    await script.run_cwfs()\n",
    "    end_time=time.time()\n",
    "    print('WFE fitting for visitIDs {0} and {1} took {2:0.3f} seconds'.format(script.intra_visit_id, script.extra_visit_id,end_time-start_time)) # 56.7s\n",
    "\n",
    "    # Display fitting results?\n",
    "    if (False):\n",
    "        # plot zernikes\n",
    "        x = np.arange(9)+4\n",
    "        plt.plot(x, script.algo.zer4UpNm[:9], 'o-', label=f'{script.dz}')\n",
    "        xlim = plt.xlim()\n",
    "        plt.plot(np.arange(15), np.zeros(15)+50, 'b--')\n",
    "        plt.plot(np.arange(15), np.zeros(15)-50, 'b--')\n",
    "        plt.xlim(xlim)\n",
    "        plt.ylabel(\"Zernike coeff (nm)\")\n",
    "        plt.xlabel(\"Zernike index\")\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        \n",
    "    if (True):\n",
    "        # plot image and mask\n",
    "        fig1 = plt.figure(2, figsize=(12,8))\n",
    "        ax11 = fig1.add_subplot(121)\n",
    "        ax11.set_title(\"defocus 0.8 - intra\")\n",
    "        ax11.imshow(script.I1[0].image0)\n",
    "        ax11.contour(script.algo.pMask) \n",
    "        ax12 = fig1.add_subplot(122)\n",
    "        ax12.set_title(\"defocus 0.8 - extra\")\n",
    "        ax12.imshow(script.I2[0].image0)\n",
    "        ax12.contour(script.algo.pMask) \n",
    "        \n",
    "    # Put results into data structure \n",
    "    df2.loc[df2.index[n],('zern_defocus_nm')] = script.algo.zer4UpNm[0]\n",
    "    df2.loc[df2.index[n],('zern_astig_oblique_nm')] = script.algo.zer4UpNm[1] # once labeled x-astigmatism\n",
    "    df2.loc[df2.index[n],('zern_astig_vertical_nm')] = script.algo.zer4UpNm[2]\n",
    "    df2.loc[df2.index[n],('zern_coma_vertical_nm')] = script.algo.zer4UpNm[3] # formerly x-coma\n",
    "    df2.loc[df2.index[n],('zern_coma_horizontal_nm')]= script.algo.zer4UpNm[4] # formerly y-coma\n",
    "    df2.loc[df2.index[n],('zern_trefoil_vertical_nm')] = script.algo.zer4UpNm[5]  # once labeled xtrefoil\n",
    "    df2.loc[df2.index[n],('zern_trefoil_oblique_nm')] = script.algo.zer4UpNm[6]\n",
    "    df2.loc[df2.index[n],('zern_spherical_nm')] = script.algo.zer4UpNm[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to CSV file\n",
    "filename=\"data/\"+date+'_'+test+\"_\"+run+\"_data_with_WFE_in_zerns.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get M1 mirror data and fit a plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmd = await efd_client.select_time_series(\"lsst.sal.PMD.position\", [\"position0\", \"position1\", \"position2\", \"position3\", \"position4\"], t1_set, t2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file (written using code above)\n",
    "df3 = pd.read_csv(filename, index_col=0)\n",
    "df3.index=pd.to_datetime(df3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=rendezvous_dataframes(df3, pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position0_offset = (df4.position0[0])\n",
    "position1_offset = (df4.position1[0])\n",
    "position2_offset = (df4.position2[0])\n",
    "position3_offset = (df4.position3[0])\n",
    "position4_offset = (df4.position4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "arr_len = len(df4.position0)\n",
    "coeff_arr = np.zeros((arr_len,3))\n",
    "theta_arr = np.zeros((arr_len))\n",
    "phi_arr = np.zeros((arr_len))\n",
    "piston_arr = np.zeros((arr_len))\n",
    "for i in np.arange(arr_len):\n",
    "\n",
    "    # X, Y, Z - measured from solidmodel\n",
    "    set2=np.array((  41.0, 468.0, (df4.position2[i]-position2_offset)))\n",
    "    set3=np.array(( 384.0,-269.0, (df4.position3[i]-position3_offset)))\n",
    "    set4=np.array((-425.0,-198.0, (df4.position4[i]-position4_offset)))\n",
    "\n",
    "    # Vector PQ crossed with Vector PR\n",
    "    normal = np.cross(set3-set2,set4-set2) # gives a,b,c\n",
    "    #print(f'normal is {normal}')\n",
    "#     theta_arr[i] = (np.pi/2 + np.arctan2(normal[2],normal[0])) * 206265 # arcsec\n",
    "#     phi_arr[i] = (np.pi/2 + np.arctan2(normal[2],normal[1])) * 206265   # arcsec\n",
    "#     piston_arr[i] = normal[2]\n",
    "    \n",
    "#     => a * (x - x0) + b * (y - y0) + c * (z - z0) = 0.\n",
    "# => a * x - a * x0 + b * y - b * y0 + c * z - c * z0 = 0.\n",
    "# => a * x + b * y + c * z + (- a * x0 - b * y0 - c * z0) = 0. # D is the last terms\n",
    "    D= -normal[0]*set2[0] - normal[1]*set2[1] - normal[2]*set2[2]  # Constant in plane equation\n",
    "    # equation \n",
    "    \n",
    "    phi_from_normal = (np.pi/2+np.arctan2(normal[2], normal[1])) * 206265\n",
    "    theta_from_normal = (np.pi/2+np.arctan2(normal[2], normal[0])) * 206265\n",
    "    # find z at the origin to represent piston\n",
    "    Z_origin = -D/normal[2]\n",
    "    \n",
    "    # Measure rotation about the Y-axis (perpendicular to elevation)\n",
    "    # So this is TIP and should result in motion in azimuth\n",
    "    # get slope by looking at Y=0, X=400\n",
    "    x_pt=400; y_pt=0\n",
    "    #Z_at_x_pt= C[0]*x_pt + C[1]*0.0 + C[2]\n",
    "    Z_at_x_pt= (-D - normal[0]*x_pt - normal[1]*0.0)/normal[2]\n",
    "    theta = np.arctan2(Z_at_x_pt-Z_origin, x_pt) * 206265 # arcsec\n",
    "        \n",
    "    # Measure rotation about the X-axis (aligned to elevation)\n",
    "    # this is TILT and should result in motion in elevation\n",
    "    # get slope by looking at Y=0, X=400    \n",
    "    x_pt=0; y_pt=400\n",
    "    Z_at_y_pt= (-D - normal[0]*x_pt - normal[1]*y_pt)/normal[2]\n",
    "    phi = np.arctan2(Z_at_y_pt-Z_origin, y_pt) * 206265 # arcsec\n",
    "\n",
    "    theta_arr[i] = theta # arcsec\n",
    "    phi_arr[i] = phi    # arcsec\n",
    "    piston_arr[i] = Z_origin\n",
    "    \n",
    "    print(f'theta_from_normal is {theta_from_normal:0.2f}, phi_from_normal is {phi_from_normal:0.2f}')\n",
    "    print(f'theta_arr is {theta_arr[i]:0.2f} [arcsec], phi_arr is {phi_arr[i]:0.2f} [arcsec]')\n",
    "#     if i == 1:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['m1_tip']=theta_arr\n",
    "df4['m1_tilt']=phi_arr\n",
    "df4['m1_piston']=piston_arr\n",
    "\n",
    "df4['m1_y_pos']=(df4.position0-position0_offset)*np.cos(10*np.pi/180)\n",
    "df4['m1_x_pos']=(df4.position1-position1_offset)*np.cos(10*np.pi/180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to CSV file\n",
    "filename=\"data/\"+date+'_'+test+\"_\"+run+\"_data_with_WFE_and_m1_pos.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the M1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file (written using code above)\n",
    "filename=\"data/\"+date+'_'+test+\"_\"+run+\"_data_with_WFE_and_m1_pos.csv\"\n",
    "df4 = pd.read_csv(filename, index_col=0)\n",
    "df4.index=pd.to_datetime(df4.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_height=5\n",
    "fig_width=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nwide=3; nhigh=3\n",
    "fig, (row1,row2,row3) = plt.subplots(nhigh, nwide, figsize=(nwide+fig_width, nhigh*fig_height))\n",
    "fig.suptitle('Rows are')\n",
    "xvals = (df4.m1_x_pos) # um\n",
    "yvals = df4.el\n",
    "\n",
    "row1[0].plot(xvals, yvals, 'o-')\n",
    "row1[0].set_ylabel('Elevation [deg]')\n",
    "row1[0].set_xlabel('M1 X-position [mm]')\n",
    "\n",
    "xvals=df4.y\n",
    "row1[1].plot(xvals,yvals, '.-')\n",
    "row1[1].set_xlabel('Hexapod Y-position [mm]')\n",
    "\n",
    "\n",
    "xvals = (df4.m1_tip) # um\n",
    "row1[2].plot(xvals, yvals, 'o-')\n",
    "row1[2].set_xlabel('M1 tip [arcsec]')\n",
    "\n",
    "\n",
    "xvals = (df4.m1_y_pos) # mm\n",
    "row2[0].plot(xvals, yvals, 'o-')\n",
    "row2[0].set_ylabel('Elevation [deg]')\n",
    "row2[0].set_xlabel('M1 X-position [mm]')\n",
    "\n",
    "xvals=df4.x\n",
    "row2[1].plot(xvals,yvals, '.-')\n",
    "row2[1].set_xlabel('Hexapod X-position [mm]')\n",
    "\n",
    "xvals = (df4.m1_tilt) # um\n",
    "row2[2].plot(xvals, yvals, 'o-')\n",
    "row2[2].set_xlabel('M1 tilt [arcsec]')\n",
    "\n",
    "xvals = (df4.m1_piston) # mm\n",
    "row3[0].plot(xvals, yvals, 'o-')\n",
    "row3[0].set_xlabel('M1 Z-position [mm]')\n",
    "\n",
    "xvals=df4.z\n",
    "row3[1].plot(xvals,yvals, '.-')\n",
    "row3[1].set_xlabel('Hexapod Z-position [mm]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nwide=4; nhigh=3\n",
    "fig, (row1,row2,row3) = plt.subplots(nhigh, nwide, figsize=(nwide+fig_width, nhigh*fig_height))\n",
    "fig.suptitle('Rows are')\n",
    "xvals = (df4.m1_x_pos) # um\n",
    "yvals = df4.el\n",
    "\n",
    "row1[0].plot(xvals, yvals, 'o-')\n",
    "row1[0].set_ylabel('Elevation [deg]')\n",
    "row1[0].set_xlabel('M1 X-position [mm]')\n",
    "\n",
    "xvals=df4.y\n",
    "row1[1].plot(xvals,yvals, '.-')\n",
    "row1[1].set_xlabel('Hexapod Y-position [mm]')\n",
    "\n",
    "xvals = (df4.m1_tip) # um   - Tip should mean ~azimuth motion\n",
    "row1[2].plot(xvals, yvals, 'o-')\n",
    "row1[2].set_xlabel('M1 tip [arcsec]')\n",
    "\n",
    "xvals = (df4.zern_trefoil_vertical_nm) # vertical\n",
    "row1[3].plot(xvals, yvals, 'o-')\n",
    "row1[3].set_xlabel('Trefoil Vertical[nm]')\n",
    "\n",
    "xvals = (df4.m1_y_pos) # mm\n",
    "row2[0].plot(xvals, yvals, 'o-')\n",
    "row2[0].set_ylabel('Elevation [deg]')\n",
    "row2[0].set_xlabel('M1 X-position [mm]')\n",
    "\n",
    "xvals=df4.x\n",
    "row2[1].plot(xvals,yvals, '.-')\n",
    "row2[1].set_xlabel('Hexapod X-position [mm]')\n",
    "\n",
    "xvals = (df4.m1_tilt) # um\n",
    "row2[2].plot(xvals, yvals, 'o-')\n",
    "row2[2].set_xlabel('M1 tilt [arcsec]')\n",
    "\n",
    "xvals = (df4.zern_trefoil_oblique_nm) # oblique\n",
    "row2[3].plot(xvals, yvals, 'o-')\n",
    "row2[3].set_xlabel('Trefoil Oblique [nm]')\n",
    "\n",
    "xvals = (df4.m1_piston) # mm\n",
    "row3[0].plot(xvals, yvals, 'o-')\n",
    "row3[0].set_ylabel('Elevation [deg]')\n",
    "row3[0].set_xlabel('M1 Z-position [mm]')\n",
    "\n",
    "xvals=df4.z\n",
    "row3[1].plot(xvals,yvals, '.-')\n",
    "row3[1].set_xlabel('Hexapod Z-position [mm]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nwide=3; nhigh=3\n",
    "fig, (row1,row2,row3) = plt.subplots(nhigh, nwide, figsize=(nwide+fig_width, nhigh*fig_height))\n",
    "fig.suptitle('Rows are')\n",
    "xvals = (df4.zern_defocus_nm) # nm\n",
    "yvals = df4.el\n",
    "\n",
    "row1[0].plot(xvals, yvals, 'o-')\n",
    "row1[0].set_ylabel('Elevation [deg]')\n",
    "row1[0].set_xlabel('Defocus [nm]')\n",
    "row1[0].annotate(f'$\\sigma$ = {np.std(xvals):0.1f}',(0.75,0.9), xycoords='axes fraction',)\n",
    "\n",
    "xvals = (df4.zern_spherical_nm) # nm\n",
    "row1[1].plot(xvals, yvals, 'o-')\n",
    "row1[1].set_xlabel('Spherical [nm]')\n",
    "row1[1].annotate(f'$\\sigma$ = {np.std(xvals):0.1f}',(0.75,0.9), xycoords='axes fraction',)\n",
    "\n",
    "xvals = (df4.zern_astig_vertical_nm) # nm\n",
    "row2[0].plot(xvals, yvals, 'o-')\n",
    "row2[0].set_ylabel('Elevation [deg]')\n",
    "row2[0].set_xlabel('Vertical Astigmatism [nm]')\n",
    "row2[0].annotate(f'$\\sigma$ = {np.std(xvals):0.1f}',(0.75,0.9), xycoords='axes fraction',)\n",
    "\n",
    "xvals = (df4.zern_coma_vertical_nm) # nm\n",
    "row2[1].plot(xvals, yvals, 'o-')\n",
    "row2[1].set_xlabel('Vertical Coma [nm]')\n",
    "row2[1].annotate(f'$\\sigma$ = {np.std(xvals):0.1f}',(0.75,0.9), xycoords='axes fraction',)\n",
    "\n",
    "xvals = (df4.zern_trefoil_vertical_nm) # nm\n",
    "row2[2].plot(xvals, yvals, 'o-')\n",
    "row2[2].set_xlabel('Vertical Trefoil [nm]')\n",
    "row2[2].annotate(f'$\\sigma$ = {np.std(xvals):0.1f}',(0.75,0.9), xycoords='axes fraction',)\n",
    "\n",
    "xvals = (df4.zern_astig_oblique_nm) # nm\n",
    "row3[0].plot(xvals, yvals, 'o-')\n",
    "row3[0].set_ylabel('Elevation [deg]')\n",
    "row3[0].set_xlabel('Oblique Astigmatism [nm]')\n",
    "row3[0].annotate(f'$\\sigma$ = {np.std(xvals):0.1f}',(0.75,0.9), xycoords='axes fraction',)\n",
    "\n",
    "xvals = (df4.zern_coma_horizontal_nm) # nm\n",
    "row3[1].plot(xvals, yvals, 'o-')\n",
    "row3[1].set_xlabel('Horizontal Coma [nm]')\n",
    "row3[1].annotate(f'$\\sigma$ = {np.std(xvals):0.1f}',(0.75,0.9), xycoords='axes fraction',)\n",
    "\n",
    "xvals = (df4.zern_trefoil_oblique_nm) # nm\n",
    "row3[2].plot(xvals, yvals, 'o-')\n",
    "row3[2].set_xlabel('Oblique Trefoil [nm]')\n",
    "row3[2].annotate(f'$\\sigma$ = {np.std(xvals):0.1f}',(0.75,0.9), xycoords='axes fraction',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
